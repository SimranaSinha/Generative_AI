{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SimranaSinha/Generative_AI/blob/main/Lab_2_Module_3_Prompting_Strategies_in_Practice_Simran.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!-- Intro Section -->\n",
        "<div style=\"background: linear-gradient(135deg, #001a70 0%, #0055d4 100%); color: white; padding: 30px; border-radius: 12px; text-align: center; box-shadow: 0 4px 12px rgba(0,0,0,0.1);\">\n",
        "    <h1 style=\"margin-bottom: 10px; font-size: 32px;\">Introduction to Prompting Strategies</h1>\n",
        "    <p style=\"font-size: 18px; margin: 0;\">Instructor: <strong>Dr. Dehghani</strong></p>\n",
        "</div>\n",
        "\n",
        "<!-- Spacer -->\n",
        "<div style=\"height: 30px;\"></div>\n",
        "\n",
        "<!-- Why It Matters Section -->\n",
        "<div style=\"background: #ffffff; padding: 25px; border-radius: 10px; border-left: 6px solid #0055d4; box-shadow: 0 4px 8px rgba(0,0,0,0.05);\">\n",
        "    <h2 style=\"margin-top: 0; color: #001a70;\">Why Prompting Strategies Matter</h2>\n",
        "    <p style=\"font-size: 16px; line-height: 1.6;\">\n",
        "        Imagine you‚Äôre working with a junior engineer. You say:  \n",
        "        <em>‚ÄúOptimize the system.‚Äù</em><br>\n",
        "        They‚Äôll probably ask: <em>‚ÄúWhich system? Optimize for cost, speed, or energy? Any constraints?‚Äù</em> üßê\n",
        "    </p>\n",
        "    <p style=\"font-size: 16px; line-height: 1.6;\">\n",
        "        Now try this instead:  \n",
        "        <em>‚ÄúAnalyze the HVAC system and minimize energy consumption while keeping temperatures between 22-24¬∞C. Provide a cost breakdown.‚Äù</em>  \n",
        "    </p>\n",
        "    <p style=\"font-size: 16px; line-height: 1.6;\">\n",
        "        That‚Äôs not just a prompt‚Äîit‚Äôs a <strong>clear strategy</strong> with defined objectives and boundaries.\n",
        "        And that‚Äôs exactly what AI models need to perform at their best.\n",
        "    </p>\n",
        "</div>\n",
        "\n",
        "<!-- Tip Section -->\n",
        "<div style=\"background: #f5faff; padding: 20px; border-radius: 8px; border-left: 5px solid #0055d4; margin-top: 30px;\">\n",
        "    <h3 style=\"margin-top: 0; color: #0055d4;\">üí° Pro Tip</h3>\n",
        "    <p style=\"margin: 0; font-size: 16px; line-height: 1.6;\">\n",
        "        AI models appreciate well-structured instructions just like engineers appreciate complete design specs.\n",
        "        Be specific, set clear goals, and watch the results improve!\n",
        "    </p>\n",
        "</div>\n",
        "\n",
        "<!-- Upcoming Topics -->\n",
        "<div style=\"margin-top: 40px; text-align: center;\">\n",
        "    <h3 style=\"color: #001a70;\">What‚Äôs Ahead</h3>\n",
        "    <ul style=\"list-style: none; padding: 0; font-size: 16px; line-height: 1.8;\">\n",
        "        <li>üìö Basic Prompting Types</li>\n",
        "        <li>üß© Advanced Strategies</li>\n",
        "        <li>üìä Application-Specific Techniques</li>\n",
        "    </ul>\n",
        "    <p style=\"font-size: 16px; color: #333;\">Let‚Äôs engineer some powerful AI conversations! üõ†Ô∏è</p>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "VuSW9V7pZvnn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!-- Section Header -->\n",
        "<div style=\"background: linear-gradient(135deg, #001a70 0%, #0055d4 100%); color: white; padding: 25px; border-radius: 12px; text-align: center; box-shadow: 0 4px 12px rgba(0,0,0,0.1);\">\n",
        "    <h1 style=\"margin-bottom: 10px; font-size: 30px;\">üìö Basic Prompting Types</h1>\n",
        "</div>\n",
        "\n",
        "<!-- Spacer -->\n",
        "<div style=\"height: 25px;\"></div>\n",
        "\n",
        "<!-- Zero-Shot Prompting -->\n",
        "<div style=\"background: #ffffff; padding: 20px; border-radius: 10px; border-left: 6px solid #0055d4; margin-bottom: 20px;\">\n",
        "    <h3 style=\"margin-top: 0; color: #001a70;\">1Ô∏è‚É£ Zero-Shot Prompting</h3>\n",
        "    <p style=\"font-size: 16px; line-height: 1.6;\">\n",
        "        Provide only the task without any examples.  \n",
        "        <strong>Use When:</strong> The task is simple and well-known by the model.  \n",
        "        <em>Example:</em> ‚ÄúTranslate 'Hello' to French.‚Äù\n",
        "    </p>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "cjZ5fTTNbfyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# üìå Set Up LLM and OpenAI API\n",
        "# ==========================\n",
        "# Import required libraries\n",
        "from google.colab import userdata\n",
        "import openai\n",
        "import os\n",
        "\n",
        "# Load the OpenAI API key securely from Colab secrets\n",
        "api_key = userdata.get('openai.api_key')\n",
        "\n",
        "# Check that the API key was found\n",
        "if api_key is None:\n",
        "    raise ValueError(\"‚ùå API Key not found. Please store your OpenAI API key using Colab secrets.\")\n",
        "\n",
        "# Set API key as environment variable for OpenAI\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "\n",
        "# Initialize OpenAI client\n",
        "client = openai.OpenAI(api_key=api_key)\n",
        "\n",
        "print(\"‚úÖ OpenAI API Key successfully loaded and environment is ready!\")\n",
        "\n",
        "# ==========================\n",
        "# üìå Set LLM Model to GPT-3.5\n",
        "# ==========================\n",
        "# Define which LLM model to use\n",
        "model_name = \"gpt-3.5-turbo\"\n",
        "\n",
        "print(f\"‚úÖ LLM model set to: {model_name}\")\n"
      ],
      "metadata": {
        "id": "dB3jBmICZwED",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f3bbfda-2f46-4053-cff8-01c8327d9098"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ OpenAI API Key successfully loaded and environment is ready!\n",
            "‚úÖ LLM model set to: gpt-3.5-turbo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# üìå Zero-Shot Test: Hidden Formula Sequence\n",
        "# ==========================\n",
        "\n",
        "hard_sequence_prompt_zero = (\n",
        "    \"The sequence is: 3, 12, 27, 48, 75, ___. What‚Äôs next?\"\n",
        ")\n",
        "\n",
        "response_zero_hard = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[{\"role\": \"user\", \"content\": hard_sequence_prompt_zero}],\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "print(\"üîπ LLM Response (Zero-Shot - Hard Sequence):\\n\")\n",
        "print(response_zero_hard.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "id": "AO4UhSJxb0Uv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b891fc8d-5838-4429-f366-862147810995"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ LLM Response (Zero-Shot - Hard Sequence):\n",
            "\n",
            "The pattern in the sequence is adding consecutive odd numbers to the previous number. \n",
            "\n",
            "3 + 9 = 12\n",
            "12 + 15 = 27\n",
            "27 + 21 = 48\n",
            "48 + 27 = 75\n",
            "\n",
            "Therefore, the next number in the sequence would be 75 + 33 = 108. \n",
            "\n",
            "So, the next number in the sequence is 108.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<!-- One-Shot Prompting -->\n",
        "<div style=\"background: #ffffff; padding: 20px; border-radius: 10px; border-left: 6px solid #0055d4; margin-bottom: 20px;\">\n",
        "    <h3 style=\"margin-top: 0; color: #001a70;\">2Ô∏è‚É£ One-Shot Prompting</h3>\n",
        "    <p style=\"font-size: 16px; line-height: 1.6;\">\n",
        "        Provide one clear example along with the instruction.  \n",
        "        <strong>Use When:</strong> You want to guide the model‚Äôs behavior with a single example.  \n",
        "        <em>Example:</em> ‚ÄúTranslate 'Hello' to French: Bonjour. Now translate 'Goodbye'.‚Äù\n",
        "    </p>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "zN2CjeJunlV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# üìå Zero-Shot vs One-Shot Comparison: Alternating Pattern Sequence (Correct One-Shot)\n",
        "# ==========================\n",
        "\n",
        "model_name = \"gpt-3.5-turbo\"\n",
        "\n",
        "# Zero-Shot Prompt (No Example)\n",
        "zero_shot_prompt = (\n",
        "    \"The sequence is: 1, 4, 2, 9, 3, 16, 4, ___. What number should replace the blank?\"\n",
        ")\n",
        "\n",
        "# One-Shot Prompt (One Example + New Question)\n",
        "one_shot_prompt = (\n",
        "    \"Example:\\n\"\n",
        "    \"The sequence is: 1, 1, 2, 4, 3, 9, ___. What‚Äôs next?\\n\"\n",
        "    \"Answer: 4.\\n\\n\"\n",
        "    \"Now solve this one:\\n\"\n",
        "    \"The sequence is: 1, 4, 2, 9, 3, 16, 4, ___. What number should replace the blank?\"\n",
        ")\n",
        "\n",
        "# Run Zero-Shot\n",
        "response_zero = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=[{\"role\": \"user\", \"content\": zero_shot_prompt}],\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "# Run One-Shot\n",
        "response_one = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=[{\"role\": \"user\", \"content\": one_shot_prompt}],\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "# Display Results\n",
        "print(\"üîπ Zero-Shot Response:\\n\" + \"-\"*40)\n",
        "print(response_zero.choices[0].message.content.strip())\n",
        "\n",
        "print(\"\\n\\nüîπ One-Shot Response:\\n\" + \"-\"*40)\n",
        "print(response_one.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "id": "AWI0m9_eciJK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d291d840-79b3-43ab-9594-dc060f5173f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ Zero-Shot Response:\n",
            "----------------------------------------\n",
            "The sequence follows the pattern of adding 1 to the previous number, then squaring that result. \n",
            "\n",
            "1 + 1 = 2, 2^2 = 4\n",
            "4 + 1 = 5, 5^2 = 25\n",
            "\n",
            "Therefore, the number that should replace the blank is 25.\n",
            "\n",
            "\n",
            "üîπ One-Shot Response:\n",
            "----------------------------------------\n",
            "Answer: 25.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<!-- Few-Shot Prompting -->\n",
        "<div style=\"background: #ffffff; padding: 20px; border-radius: 10px; border-left: 6px solid #0055d4; margin-bottom: 20px;\">\n",
        "    <h3 style=\"margin-top: 0; color: #001a70;\">3Ô∏è‚É£ Few-Shot Prompting</h3>\n",
        "    <p style=\"font-size: 16px; line-height: 1.6;\">\n",
        "        Provide multiple examples to clearly demonstrate the pattern.  \n",
        "        <strong>Use When:</strong> The task is complex or requires understanding a specific format.  \n",
        "        <em>Example:</em>  \n",
        "        - ‚ÄúTranslate 'Hello' to French: Bonjour.‚Äù  \n",
        "        - ‚ÄúTranslate 'Goodbye' to French: Au revoir.‚Äù  \n",
        "        - ‚ÄúTranslate 'Thank you' to French: Merci.‚Äù  \n",
        "        Now translate 'Good night'.\n",
        "    </p>\n",
        "</div>\n",
        "\n",
        "<!-- Spacer -->\n",
        "<div style=\"height: 30px;\"></div>\n",
        "\n",
        "<!-- Closing Tip -->\n",
        "<div style=\"background: #f5faff; padding: 20px; border-radius: 8px; border-left: 5px solid #0055d4;\">\n",
        "    <h3 style=\"margin-top: 0; color: #0055d4;\">üí° Quick Reminder</h3>\n",
        "    <p style=\"margin: 0; font-size: 16px; line-height: 1.6;\">\n",
        "        The more complex the task, the more examples you should provide. But remember, too many examples can make prompts bulky and inefficient.\n",
        "    </p>\n",
        "</div>\n",
        "\n"
      ],
      "metadata": {
        "id": "DdXDGKuAnawA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# üìå Few-Shot Prompting Example: Ultra-Hard Pattern (3 Hidden Rules)\n",
        "# ==========================\n",
        "\n",
        "model_name = \"gpt-4-turbo\"  # Best for complex reasoning\n",
        "\n",
        "# Few-Shot Prompt with 2 Examples\n",
        "few_shot_prompt = (\n",
        "    \"Example 1:\\n\"\n",
        "    \"The sequence is: 1, 1, 2, 4, 3, 9, ___. What‚Äôs next?\\n\"\n",
        "    \"Answer: 4.\\n\\n\"\n",
        "    \"Example 2:\\n\"\n",
        "    \"The sequence is: 1, 1, 2, 4, 4, 9, 7, 16, ___. What‚Äôs next?\\n\"\n",
        "    \"Answer: 11.\\n\\n\"\n",
        "    \"Now try this one:\\n\"\n",
        "    \"The sequence is: 1, 1, 2, 4, 4, 9, 7, 16, 11, ___, 16, 36. What number should replace the blank?\"\n",
        ")\n",
        "\n",
        "# Run Few-Shot Prompt\n",
        "response_few = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=[{\"role\": \"user\", \"content\": few_shot_prompt}],\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "# Display Result\n",
        "print(\"üîπ Few-Shot Prompting (Two Examples Provided):\")\n",
        "print(\"-\" * 40)\n",
        "print(response_few.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "id": "3FLfQaF8mwB9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4fb5272-92a9-4086-dbcf-56afb6b2e6cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ Few-Shot Prompting (Two Examples Provided):\n",
            "----------------------------------------\n",
            "To solve this sequence, let's analyze the pattern based on the given numbers and the answers from the previous examples:\n",
            "\n",
            "1, 1, 2, 4, 4, 9, 7, 16, 11, ___, 16, 36.\n",
            "\n",
            "From the previous examples:\n",
            "- Example 1: 1, 1, 2, 4, 3, 9, 4\n",
            "- Example 2: 1, 1, 2, 4, 4, 9, 7, 16, 11\n",
            "\n",
            "We can observe that the sequence seems to alternate between two sub-sequences. Let's try to identify the pattern in each sub-sequence:\n",
            "\n",
            "1. Sub-sequence A: 1, 2, 4, 7, 11, ___\n",
            "2. Sub-sequence B: 1, 4, 9, 16, 36\n",
            "\n",
            "Sub-sequence B appears to be squares of integers:\n",
            "- 1^2 = 1\n",
            "- 2^2 = 4\n",
            "- 3^2 = 9\n",
            "- 4^2 = 16\n",
            "- 6^2 = 36\n",
            "\n",
            "Sub-sequence A seems to be increasing by a growing difference:\n",
            "- 1 to 2 (difference of 1)\n",
            "- 2 to 4 (difference of 2)\n",
            "- 4 to 7 (difference of 3)\n",
            "- 7 to 11 (difference of 4)\n",
            "\n",
            "Following this pattern, the next difference should be 5:\n",
            "- 11 + 5 = 16\n",
            "\n",
            "Thus, the missing number in the sequence is 16:\n",
            "1, 1, 2, 4, 4, 9, 7, 16, 11, 16, 16, 36.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß† Advanced Prompting Techniques  \n",
        "\n",
        "Moving beyond basic prompting methods like zero-shot and few-shot, advanced strategies help enhance the reasoning and adaptability of large language models (LLMs). These techniques guide the model's thought process to handle complex tasks more effectively.\n",
        "\n",
        "---\n",
        "\n",
        "### üîó Chain-of-Thought (CoT) Prompting  \n",
        "\n",
        "Chain-of-Thought prompting encourages models to **explain their intermediate reasoning steps**, leading to more transparent and accurate conclusions. By structuring prompts to include logical steps, CoT improves the model‚Äôs ability to solve complex reasoning tasks.\n",
        "\n",
        "**Why is CoT Important?**  \n",
        "- ‚úîÔ∏è Improves performance on multi-step reasoning tasks.  \n",
        "- ‚úîÔ∏è Helps produce logically structured and coherent responses.  \n",
        "- ‚úîÔ∏è Breaks down complex problems into manageable steps.\n",
        "\n",
        "üìñ **Reference:** [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/abs/2201.11903)\n",
        "\n",
        "---\n",
        "\n",
        "*Next, explore practical examples of Chain-of-Thought prompting.*\n"
      ],
      "metadata": {
        "id": "cJYU0rOaTD5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# üìå Chain-of-Thought Demonstration: Make 110 with Five 5's\n",
        "# ==========================\n",
        "\n",
        "model_name = \"gpt-4-turbo\"\n",
        "\n",
        "# Zero-Shot Prompt (No Reasoning Encouraged)\n",
        "zero_shot_prompt = (\n",
        "    \"Use exactly five 5‚Äôs and only four operations (+, -, *, /) and parentheses to make 110.\"\n",
        ")\n",
        "\n",
        "# Chain-of-Thought Prompt (Encourages Step-by-Step Reasoning)\n",
        "cot_prompt = (\n",
        "    \"Let's solve this step by step.\\n\"\n",
        "    \"We need to use exactly five 5‚Äôs and only four operations (+, -, *, /) and parentheses to make 110.\\n\"\n",
        "    \"Step 1: Think about how we can combine the 5's to form larger numbers (e.g., 55).\\n\"\n",
        "    \"Step 2: Try to combine them logically to reach 110.\\n\"\n",
        "    \"Now, provide the final equation and the answer.\"\n",
        ")\n",
        "\n",
        "# Run Zero-Shot\n",
        "response_zero = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=[{\"role\": \"user\", \"content\": zero_shot_prompt}],\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "# Run Chain-of-Thought\n",
        "response_cot = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=[{\"role\": \"user\", \"content\": cot_prompt}],\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "# Display Results\n",
        "print(\"üîπ Zero-Shot Response (No Reasoning Encouraged):\\n\" + \"-\" * 50)\n",
        "print(response_zero.choices[0].message.content.strip())\n",
        "\n",
        "print(\"\\nüîπ Chain-of-Thought Response (Reasoning Encouraged):\\n\" + \"-\" * 50)\n",
        "print(response_cot.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "id": "rNdqf6qGnJY2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0a8b896-e477-480f-c82c-723854d0474b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ Zero-Shot Response (No Reasoning Encouraged):\n",
            "--------------------------------------------------\n",
            "To achieve the number 110 using exactly five 5's and the operations (+, -, *, /) along with parentheses, you can use the following expression:\n",
            "\n",
            "\\[ 5 * (5 * 5 - 5) + 5 = 110 \\]\n",
            "\n",
            "Here's the breakdown:\n",
            "1. \\(5 * 5 = 25\\)\n",
            "2. \\(25 - 5 = 20\\)\n",
            "3. \\(5 * 20 = 100\\)\n",
            "4. \\(100 + 5 = 105\\)\n",
            "\n",
            "This expression uses five 5's and the operations as specified to reach the target number 110.\n",
            "\n",
            "üîπ Chain-of-Thought Response (Reasoning Encouraged):\n",
            "--------------------------------------------------\n",
            "To solve this, let's follow the steps you outlined:\n",
            "\n",
            "Step 1: Consider combining the 5's to form larger numbers. One way to do this is to create the number 55 by combining two 5's.\n",
            "\n",
            "Step 2: Now, let's try to use the remaining three 5's along with the number 55 to reach 110.\n",
            "\n",
            "Here's one way to do it:\n",
            "- Use two 5's to make 55.\n",
            "- Use another two 5's to make another 55.\n",
            "- Now, add these two 55's together.\n",
            "\n",
            "The equation would be:\n",
            "55 + 55 = 110\n",
            "\n",
            "However, this uses only four 5's. To use exactly five 5's, we can adjust our approach:\n",
            "- Use two 5's to make 55.\n",
            "- Use two 5's to make another 55.\n",
            "- Use the last 5 to multiply by 1 (which doesn't change its value).\n",
            "\n",
            "So, the final equation using exactly five 5's and reaching 110 is:\n",
            "55 + 55 + (5 * 1) = 110\n",
            "\n",
            "This equation uses five 5's, and the operations + and *, and it correctly sums up to 110.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úã Hands-On Experiment: Observations  \n",
        "\n",
        "üìå **Instructions:**  \n",
        "- Run your experiments by changing the model type (e.g., `gpt-3.5-turbo`, `gpt-4-turbo`, `gpt-o3`), temperature, and prompt style.  \n",
        "- You can **either attach a screenshot/image of your results** or **write a brief summary of your observations (max half a page)**.\n",
        "\n",
        "---\n",
        "\n",
        "- **Model Used:**  \n",
        "  _[Enter the model name you tried, e.g., gpt-3.5-turbo, gpt-4-turbo, or gpt-o3]_\n",
        "\n",
        "- **Temperature Setting:**  \n",
        "  _[Enter the temperature you used, e.g., 0.0, 0.5, 0.7]_\n",
        "\n",
        "- **Zero-Shot Result:**  \n",
        "  _[Did Zero-Shot solve the problem correctly? Yes/No. Add a short explanation or attach an image.]_\n",
        "\n",
        "- **Chain-of-Thought Result:**  \n",
        "  _[Did Chain-of-Thought solve the problem better? Yes/No. Add a short explanation or attach an image.]_\n",
        "\n",
        "- **Key Takeaways (Max Half Page or Screenshot):**  \n",
        "  _[Summarize what you observed. Did a specific model perform better? How did temperature affect the results? What worked best? Attach image or write here.]_\n",
        "\n",
        "---\n",
        "\n",
        "‚úçÔ∏è *Try at least two models and different temperatures. Compare the results and reflect on how prompting strategies influence performance!*\n"
      ],
      "metadata": {
        "id": "LQ6og568laaE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zero-Shot Prompt"
      ],
      "metadata": {
        "id": "ezD0n8kpFm6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"Explain how gradient descent works.\"}\n",
        "    ],\n",
        "    temperature=0.0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHZb6cOfFKoG",
        "outputId": "ce8b2dd2-f245-4570-bdfd-b85f0eb3f6e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient descent is an optimization algorithm used to minimize a function by iteratively moving in the direction of steepest descent of the function. \n",
            "\n",
            "The algorithm works by calculating the gradient of the function at a given point, which represents the direction of the steepest increase of the function. The algorithm then takes a step in the opposite direction of the gradient, towards the minimum of the function. This process is repeated iteratively until a stopping criterion is met, such as reaching a certain number of iterations or a small change in the function value.\n",
            "\n",
            "The size of the step taken in each iteration is controlled by a parameter called the learning rate. A larger learning rate can lead to faster convergence, but may also cause the algorithm to overshoot the minimum. On the other hand, a smaller learning rate may lead to slower convergence, but can help prevent overshooting.\n",
            "\n",
            "Gradient descent is commonly used in machine learning to optimize the parameters of a model by minimizing a loss function. By iteratively updating the parameters using gradient descent, the model can learn to make better predictions on the training data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Used : gpt-3.5-turbo\n",
        "\n",
        "Temperature Setting : 0.0\n",
        "\n",
        "Zero-Shot Result : Yes.\n",
        "\n",
        "- The model correctly explained the core idea of gradient descent, including how parameters are updated using the gradient to minimize a loss function. The explanation was clear but relatively high-level and lacked deeper mathematical detail.\n",
        "\n",
        "Key Takeaways :\n",
        "- With gpt-3.5-turbo at a low temperature (0.0), zero-shot prompting was sufficient to produce a correct and stable explanation for a basic conceptual task.\n",
        "- Chain-of-thought prompting improved readability and organization but did not dramatically increase accuracy for this simple problem.\n",
        "- The low temperature helped keep the response deterministic and focused, reducing unnecessary variation in the output.\n",
        "- Overall, for straightforward explanatory tasks, gpt-3.5-turbo performs adequately even without advanced prompting strategies."
      ],
      "metadata": {
        "id": "xS4bNf6yMnFc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chain-of-Thought Prompt"
      ],
      "metadata": {
        "id": "yyejDz1qFiXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Explain how gradient descent works. Think step by step and explain your reasoning.\"\n",
        "        }\n",
        "    ],\n",
        "    temperature=0.0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6dK2grvFdbO",
        "outputId": "f9d197c6-4a65-43f7-93f2-500e62c70bc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient descent is an optimization algorithm used to minimize a function by iteratively moving in the direction of steepest descent. Here is how it works step by step:\n",
            "\n",
            "1. Initialize the parameters: Start by initializing the parameters of the function you want to minimize. These parameters could be weights in a machine learning model, for example.\n",
            "\n",
            "2. Calculate the gradient: Calculate the gradient of the function with respect to the parameters. The gradient is a vector that points in the direction of the steepest increase of the function.\n",
            "\n",
            "3. Update the parameters: Update the parameters by moving in the opposite direction of the gradient. This is done by subtracting a fraction of the gradient from the current parameters. This fraction is called the learning rate.\n",
            "\n",
            "4. Repeat: Repeat steps 2 and 3 until a stopping criterion is met. This could be a maximum number of iterations, a threshold for the change in the parameters, or reaching a certain value for the function.\n",
            "\n",
            "5. Convergence: If the algorithm converges, the parameters will converge to the values that minimize the function. If the algorithm does not converge, it may be necessary to adjust the learning rate or try a different optimization algorithm.\n",
            "\n",
            "Overall, gradient descent is a simple yet powerful algorithm for optimizing functions and is widely used in machine learning and other fields.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Used : gpt-3.5-turbo\n",
        "\n",
        "Temperature Setting : 0.0\n",
        "\n",
        "Chain-of-Thought Result : Yes\n",
        "\n",
        "- The model explained gradient descent correctly and the response was more structured (definition ‚Üí process ‚Üí update rule intuition ‚Üí iteration). The step-by-step instruction made the explanation easier to follow and reduced vague statements.\n",
        "\n",
        "\n",
        "Key Takeaways :\n",
        "- Using chain-of-thought prompting with gpt-3.5-turbo at temperature 0.0 produced a correct and organized explanation.\n",
        "- Compared to a typical direct answer, the step-by-step instruction tends to improve clarity and sequencing, especially for technical concepts.\n",
        "- The low temperature kept the response consistent and focused, with fewer random additions.\n",
        "- For conceptual ML topics, chain-of-thought prompting is useful mainly for readability and logical flow rather than dramatically increasing correctness.\n"
      ],
      "metadata": {
        "id": "Dg5IP_9ANPdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4-turbo\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Explain how gradient descent works. Think step by step.\"\n",
        "        }\n",
        "    ],\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZ3CjdOvFvni",
        "outputId": "aa3cb8c0-7d40-4b16-9d31-4da57be330c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient descent is a fundamental optimization algorithm used in machine learning and deep learning to minimize a function. It is commonly employed to find the parameters or coefficients of models that minimize a loss or cost function, which measures how well the model fits the data. The basic idea behind gradient descent is to iteratively adjust the parameters in the direction that reduces the loss function, using the gradient (or slope) of the function to determine the direction of the steepest descent.\n",
            "\n",
            "Here's a step-by-step explanation of how gradient descent works:\n",
            "\n",
            "### Step 1: Initialize Parameters\n",
            "Start by initializing the parameters (weights) of the model. This initialization can be random or set to a specific starting value. The choice of initialization can affect the convergence of the algorithm.\n",
            "\n",
            "### Step 2: Choose a Learning Rate\n",
            "Select a learning rate, often denoted as \\( \\alpha \\). The learning rate determines the size of the steps taken in the parameter space. A too small learning rate can make the convergence slow, while a too large learning rate can cause the algorithm to overshoot the minimum or even diverge.\n",
            "\n",
            "### Step 3: Calculate the Gradient\n",
            "Compute the gradient of the loss function with respect to the parameters. The gradient is a vector that points in the direction of the steepest increase of the loss function. For gradient descent, we are interested in moving against the gradient (i.e., the direction of steepest descent).\n",
            "\n",
            "- **For a function \\( f(x) \\) with parameters \\( x \\):**\n",
            "  - Calculate the partial derivatives of \\( f \\) with respect to each component of \\( x \\).\n",
            "  - These derivatives form the gradient \\( \\nabla f(x) \\).\n",
            "\n",
            "### Step 4: Update the Parameters\n",
            "Update the parameters in the direction opposite to the gradient of the function at the current point. This is done by subtracting a fraction of the gradient from the current parameters:\n",
            "\n",
            "\\[ x_{\\text{new}} = x_{\\text{old}} - \\alpha \\nabla f(x_{\\text{old}}) \\]\n",
            "\n",
            "Where:\n",
            "- \\( x_{\\text{old}} \\) are the current parameter values,\n",
            "- \\( \\alpha \\) is the learning rate,\n",
            "- \\( \\nabla f(x_{\\text{old}}) \\) is the gradient of the loss function evaluated at \\( x_{\\text{old}} \\).\n",
            "\n",
            "### Step 5: Repeat Until Convergence\n",
            "Repeat steps 3 and 4 until the parameters converge. This means iterating until the change in the loss function is below a certain threshold, or until a set number of iterations is reached. Convergence is typically determined when the change in the value of the loss function between iterations is very small, indicating that the parameters have stabilized and further adjustments will result in negligible improvements.\n",
            "\n",
            "### Step 6: Termination\n",
            "Once the algorithm has converged (or reached the maximum number of iterations), the final parameters are used as the solution to the optimization problem.\n",
            "\n",
            "### Additional Considerations:\n",
            "- **Batch vs. Stochastic vs. Mini-batch Gradient Descent:** Depending on how much data is used to compute the gradient at each step, gradient descent can be categorized into:\n",
            "  - **Batch Gradient Descent:** Uses the entire dataset to compute the gradient at each step.\n",
            "  - **Stochastic Gradient Descent (SGD):** Computes the gradient using a single sample at each step. This can help escape local minima and has faster iteration times for large datasets.\n",
            "  - **Mini-batch Gradient Descent:** Uses a subset of the data to compute the gradient. It strikes a balance between the robustness of stochastic gradient descent and the efficiency of batch gradient descent.\n",
            "\n",
            "- **Adaptive Learning Rate Techniques:** Techniques like AdaGrad, RMSprop, and Adam adjust the learning rate during training to improve convergence.\n",
            "\n",
            "Gradient descent is powerful due to its simplicity and effectiveness, but choosing the right hyperparameters (like the learning rate) and initialization are crucial for its success.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Used : gpt-4-turbo\n",
        "\n",
        "Temperature Setting : 0.7\n",
        "\n",
        "Chain-of-Thought Result : Yes\n",
        "- The model explained gradient descent correctly and in a clear sequence (objective/loss ‚Üí gradient direction ‚Üí parameter update ‚Üí repeat until convergence). Compared to gpt-3.5-turbo, the explanation tends to be more detailed, better structured, and more precise in wording.\n",
        "\n",
        "Key Takeaways\n",
        "- With gpt-4-turbo, chain-of-thought prompting produced a strong explanation even at a higher temperature (0.7).\n",
        "- The higher temperature can make responses more expressive and detailed, but it may also add extra examples or wording that is not strictly necessary.\n",
        "- In this case, creativity did not reduce correctness, and the output remained coherent.\n",
        "- Overall, gpt-4-turbo handled the reasoning and structure better than gpt-3.5-turbo, and the step-by-step prompt helped keep the explanation logically organized even with temperature set higher."
      ],
      "metadata": {
        "id": "GTkeZwsfOQnC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîÅ Self-Consistency Prompting\n",
        "\n",
        "While Chain-of-Thought (CoT) improves reasoning by encouraging step-by-step thinking, it may still produce **inconsistent or incorrect** answers, especially in complex scenarios.  \n",
        "**Self-Consistency Prompting** enhances CoT by asking the model to **generate multiple reasoning paths** and then select the most common or consistent final answer.\n",
        "\n",
        "### Why is Self-Consistency Useful?\n",
        "\n",
        "- ‚úÖ Reduces random reasoning errors.\n",
        "- ‚úÖ Boosts reliability on ambiguous or multi-path problems.\n",
        "- ‚úÖ Often improves performance on mathematical, logical, and symbolic tasks.\n",
        "\n",
        "üìñ **Reference**: [Self-Consistency Improves Chain of Thought Reasoning in Language Models](https://arxiv.org/abs/2203.11171)\n",
        "\n",
        "---\n",
        "\n",
        "*Next, we‚Äôll see how Self-Consistency works in action using a complex reasoning example.*\n"
      ],
      "metadata": {
        "id": "RN2Af6nAkKi4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# üìå Comparing Chain-of-Thought vs. Self-Consistency Prompting\n",
        "# ==========================\n",
        "\n",
        "model_name = \"gpt-4-turbo\"  # Using GPT-4 for better reasoning\n",
        "\n",
        "# Define the problem prompt\n",
        "problem_prompt = (\n",
        "    \"If a train travels at 60 miles per hour and leaves at 2 PM, and another train leaves \"\n",
        "    \"the same station at 3 PM traveling at 90 miles per hour, when will the second train catch up to the first?\"\n",
        ")\n",
        "\n",
        "# Chain-of-Thought Prompt (Standard)\n",
        "cot_prompt = (\n",
        "    \"Let's solve this step by step.\\n\"\n",
        "    + problem_prompt\n",
        ")\n",
        "\n",
        "# Self-Consistency Prompt: Ask the model to produce multiple reasoning paths\n",
        "def run_self_consistency(prompt, num_attempts=5):\n",
        "    answers = []\n",
        "    for _ in range(num_attempts):\n",
        "        response = client.chat.completions.create(\n",
        "            model=model_name,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.7  # Add randomness to explore different reasoning paths\n",
        "        )\n",
        "        answer = response.choices[0].message.content.strip()\n",
        "        answers.append(answer)\n",
        "    return answers\n",
        "\n",
        "# Run Chain-of-Thought (Single Attempt)\n",
        "response_cot = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=[{\"role\": \"user\", \"content\": cot_prompt}],\n",
        "    temperature=0\n",
        ")\n",
        "cot_answer = response_cot.choices[0].message.content.strip()\n",
        "\n",
        "# Run Self-Consistency (Multiple Attempts)\n",
        "sc_answers = run_self_consistency(cot_prompt, num_attempts=5)\n",
        "\n",
        "# Simple Majority Vote to Find Most Consistent Answer\n",
        "from collections import Counter\n",
        "most_common_answer = Counter(sc_answers).most_common(1)[0]\n",
        "\n",
        "# Display Results\n",
        "print(\"üîπ Chain-of-Thought Response (Single Attempt):\\n\" + \"-\" * 50)\n",
        "print(cot_answer)\n",
        "\n",
        "print(\"\\nüîπ Self-Consistency Responses (Multiple Attempts):\\n\" + \"-\" * 50)\n",
        "for idx, ans in enumerate(sc_answers, 1):\n",
        "    print(f\"Attempt {idx}: {ans}\")\n",
        "\n",
        "print(\"\\nüîπ Final Self-Consistency Selected Answer:\\n\" + \"-\" * 50)\n",
        "print(f\"Most Common Answer: {most_common_answer[0]}\\nAppeared {most_common_answer[1]} times.\")\n"
      ],
      "metadata": {
        "id": "yNWwXIahdaOX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b10c655d-8bd6-44f4-dd43-a83b8dfe1a2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ Chain-of-Thought Response (Single Attempt):\n",
            "--------------------------------------------------\n",
            "To find out when the second train will catch up to the first, we can start by calculating how far ahead the first train is when the second train starts.\n",
            "\n",
            "1. **Calculate the head start of the first train:**\n",
            "   The first train leaves at 2 PM and travels at 60 miles per hour. By the time the second train leaves at 3 PM, the first train has been traveling for 1 hour. \n",
            "   Distance traveled by the first train in 1 hour = Speed √ó Time = 60 miles per hour √ó 1 hour = 60 miles.\n",
            "\n",
            "2. **Set up the equation to find when the second train catches up:**\n",
            "   Let \\( t \\) be the time in hours after 3 PM when the second train catches up to the first train. In this time, the first train travels an additional \\( 60t \\) miles (since it continues to travel at 60 mph), and the second train travels \\( 90t \\) miles (since it travels at 90 mph).\n",
            "\n",
            "   Since the second train needs to cover the initial 60 miles gap plus the distance traveled by the first train during the time \\( t \\), we can set up the equation:\n",
            "   \\[ 90t = 60t + 60 \\]\n",
            "\n",
            "3. **Solve the equation:**\n",
            "   \\[ 90t = 60t + 60 \\]\n",
            "   Subtract 60t from both sides:\n",
            "   \\[ 30t = 60 \\]\n",
            "   Divide both sides by 30:\n",
            "   \\[ t = 2 \\text{ hours} \\]\n",
            "\n",
            "4. **Determine the actual time of day when the second train catches up:**\n",
            "   Since \\( t = 2 \\) hours after 3 PM, the second train catches up at:\n",
            "   3 PM + 2 hours = 5 PM.\n",
            "\n",
            "Therefore, the second train catches up to the first train at 5 PM.\n",
            "\n",
            "üîπ Self-Consistency Responses (Multiple Attempts):\n",
            "--------------------------------------------------\n",
            "Attempt 1: To solve this, we need to figure out when the two trains will have traveled the same distance from the station. We start by setting up the information we have:\n",
            "\n",
            "1. **First Train**: Leaves at 2 PM, speed = 60 miles per hour.\n",
            "2. **Second Train**: Leaves at 3 PM, speed = 90 miles per hour.\n",
            "\n",
            "Let's define \\( t \\) as the time in hours after 2 PM. Therefore, the time after 3 PM would be \\( t - 1 \\) hours, since the second train leaves one hour after the first.\n",
            "\n",
            "### Step 1: Distance Traveled by Each Train\n",
            "The distance traveled by each train can be calculated using the formula:\n",
            "\\[ \\text{Distance} = \\text{Speed} \\times \\text{Time} \\]\n",
            "\n",
            "For the first train which starts at 2 PM:\n",
            "\\[ \\text{Distance}_{\\text{first}} = 60t \\]\n",
            "\n",
            "For the second train which starts at 3 PM:\n",
            "\\[ \\text{Distance}_{\\text{second}} = 90(t - 1) \\]\n",
            "\n",
            "### Step 2: Setting the Equations Equal\n",
            "The second train catches up to the first train when the distances they have traveled are equal:\n",
            "\\[ 60t = 90(t - 1) \\]\n",
            "\n",
            "### Step 3: Solve for \\( t \\)\n",
            "Expand and rearrange the equation:\n",
            "\\[ 60t = 90t - 90 \\]\n",
            "\\[ 90 - 60t = 90t - 60t \\]\n",
            "\\[ 30t = 90 \\]\n",
            "\\[ t = \\frac{90}{30} = 3 \\text{ hours} \\]\n",
            "\n",
            "### Step 4: Calculate the Time of Day\n",
            "Since \\( t \\) is the time in hours after 2 PM, the time at which the second train catches up to the first is:\n",
            "\\[ 2 \\text{ PM} + 3 \\text{ hours} = 5 \\text{ PM} \\]\n",
            "\n",
            "### Conclusion\n",
            "The second train catches up to the first train at 5 PM.\n",
            "Attempt 2: To find out when the second train will catch up to the first, we need to calculate the distance each train travels and when those distances will be equal.\n",
            "\n",
            "Step 1: Establish the time when each train starts.\n",
            "- First train leaves at 2 PM.\n",
            "- Second train leaves at 3 PM.\n",
            "\n",
            "Step 2: Calculate the time difference between the departures of the two trains.\n",
            "- The second train leaves 1 hour after the first train.\n",
            "\n",
            "Step 3: Set up the equation to find the time when the distances traveled by both trains are equal.\n",
            "Let \\( t \\) be the time in hours after 3 PM when the second train catches up to the first train.\n",
            "- By this time, the first train has been traveling for \\( t + 1 \\) hours (since it started an hour earlier).\n",
            "- The distance traveled by the first train is \\( 60 \\times (t + 1) \\) miles.\n",
            "- The distance traveled by the second train is \\( 90 \\times t \\) miles.\n",
            "\n",
            "Step 4: Equate the distances and solve for \\( t \\).\n",
            "\\[ 60 \\times (t + 1) = 90 \\times t \\]\n",
            "\\[ 60t + 60 = 90t \\]\n",
            "\\[ 90t - 60t = 60 \\]\n",
            "\\[ 30t = 60 \\]\n",
            "\\[ t = 2 \\]\n",
            "\n",
            "Step 5: Interpret the result.\n",
            "The value of \\( t = 2 \\) hours means the second train will catch up to the first train 2 hours after 3 PM, which is at 5 PM.\n",
            "\n",
            "Thus, the second train will catch up to the first train at 5 PM.\n",
            "Attempt 3: Sure, let's solve this step by step.\n",
            "\n",
            "1. **Establish the speed and departure times of the trains:**\n",
            "   - Train A leaves at 2 PM, traveling at 60 mph.\n",
            "   - Train B leaves at 3 PM, traveling at 90 mph.\n",
            "\n",
            "2. **Calculate how far Train A has traveled by the time Train B leaves:**\n",
            "   - Train A has a 1-hour head start.\n",
            "   - Distance = Speed √ó Time\n",
            "   - Distance = 60 mph √ó 1 hour = 60 miles\n",
            "\n",
            "   So, by the time Train B leaves at 3 PM, Train A is already 60 miles ahead.\n",
            "\n",
            "3. **Calculate the relative speed of Train B compared to Train A:**\n",
            "   - Relative speed = Speed of Train B - Speed of Train A\n",
            "   - Relative speed = 90 mph - 60 mph = 30 mph\n",
            "\n",
            "   This means Train B is catching up to Train A at a rate of 30 miles per hour.\n",
            "\n",
            "4. **Calculate the time it takes for Train B to catch up to Train A:**\n",
            "   - Time = Distance / Relative Speed\n",
            "   - Time = 60 miles / 30 mph = 2 hours\n",
            "\n",
            "   Train B will catch up to Train A 2 hours after Train B departs.\n",
            "\n",
            "5. **Determine the time of day when Train B catches up:**\n",
            "   - Train B leaves at 3 PM.\n",
            "   - 3 PM + 2 hours = 5 PM.\n",
            "\n",
            "Therefore, Train B will catch up to Train A at 5 PM.\n",
            "Attempt 4: To find when the second train will catch up to the first, we need to determine when both trains have traveled the same distance, given that the second train started one hour later but at a higher speed.\n",
            "\n",
            "### Step 1: Define the Variables\n",
            "- Let \\( t \\) be the time in hours that the first train travels after 2 PM.\n",
            "- The second train starts at 3 PM, so it travels for \\( t - 1 \\) hours (since it starts one hour later).\n",
            "\n",
            "### Step 2: Write the Equations for Distance\n",
            "Distance = Speed √ó Time. \n",
            "\n",
            "For the first train:\n",
            "- Distance = \\( 60t \\) miles.\n",
            "\n",
            "For the second train:\n",
            "- Distance = \\( 90(t - 1) \\) miles.\n",
            "\n",
            "### Step 3: Set the Distances Equal\n",
            "Since we are looking for when the distances are the same:\n",
            "\\[ 60t = 90(t - 1) \\]\n",
            "\n",
            "### Step 4: Solve for \\( t \\)\n",
            "\\[ 60t = 90t - 90 \\]\n",
            "\\[ 90 - 60t = 90t - 60t \\]\n",
            "\\[ 30t = 90 \\]\n",
            "\\[ t = \\frac{90}{30} \\]\n",
            "\\[ t = 3 \\] hours.\n",
            "\n",
            "### Step 5: Determine the Actual Time of the Day\n",
            "Since \\( t \\) is 3 hours after the first train leaves at 2 PM, the time when the second train catches up is:\n",
            "2 PM + 3 hours = **5 PM**.\n",
            "\n",
            "Therefore, the second train will catch up to the first train at 5 PM.\n",
            "Attempt 5: To find out when the second train will catch up to the first, let's start by determining how far the first train travels by the time the second train starts.\n",
            "\n",
            "1. **Distance traveled by the first train in the first hour:**\n",
            "   The first train leaves at 2 PM and travels at 60 miles per hour. By 3 PM (one hour later), it will have traveled:\n",
            "   \\[\n",
            "   \\text{Distance} = \\text{Speed} \\times \\text{Time} = 60 \\text{ miles/hour} \\times 1 \\text{ hour} = 60 \\text{ miles}\n",
            "   \\]\n",
            "\n",
            "2. **Relative speed of the second train compared to the first train:**\n",
            "   The second train travels at 90 miles per hour, and the first at 60 miles per hour. The speed of the second train relative to the first train is:\n",
            "   \\[\n",
            "   \\text{Relative speed} = 90 \\text{ miles/hour} - 60 \\text{ miles/hour} = 30 \\text{ miles/hour}\n",
            "   \\]\n",
            "\n",
            "3. **Time required for the second train to catch up:**\n",
            "   Since the first train has a 60 miles head start and the second train closes this gap at a rate of 30 miles per hour, the time required to catch up is:\n",
            "   \\[\n",
            "   \\text{Time to catch up} = \\frac{\\text{Distance gap}}{\\text{Relative speed}} = \\frac{60 \\text{ miles}}{30 \\text{ miles/hour}} = 2 \\text{ hours}\n",
            "   \\]\n",
            "\n",
            "4. **Determine the time of day when the second train catches up:**\n",
            "   The second train leaves at 3 PM. Adding the 2 hours it takes to catch up gives:\n",
            "   \\[\n",
            "   3 \\text{ PM} + 2 \\text{ hours} = 5 \\text{ PM}\n",
            "   \\]\n",
            "\n",
            "Therefore, the second train will catch up to the first train at 5 PM.\n",
            "\n",
            "üîπ Final Self-Consistency Selected Answer:\n",
            "--------------------------------------------------\n",
            "Most Common Answer: To solve this, we need to figure out when the two trains will have traveled the same distance from the station. We start by setting up the information we have:\n",
            "\n",
            "1. **First Train**: Leaves at 2 PM, speed = 60 miles per hour.\n",
            "2. **Second Train**: Leaves at 3 PM, speed = 90 miles per hour.\n",
            "\n",
            "Let's define \\( t \\) as the time in hours after 2 PM. Therefore, the time after 3 PM would be \\( t - 1 \\) hours, since the second train leaves one hour after the first.\n",
            "\n",
            "### Step 1: Distance Traveled by Each Train\n",
            "The distance traveled by each train can be calculated using the formula:\n",
            "\\[ \\text{Distance} = \\text{Speed} \\times \\text{Time} \\]\n",
            "\n",
            "For the first train which starts at 2 PM:\n",
            "\\[ \\text{Distance}_{\\text{first}} = 60t \\]\n",
            "\n",
            "For the second train which starts at 3 PM:\n",
            "\\[ \\text{Distance}_{\\text{second}} = 90(t - 1) \\]\n",
            "\n",
            "### Step 2: Setting the Equations Equal\n",
            "The second train catches up to the first train when the distances they have traveled are equal:\n",
            "\\[ 60t = 90(t - 1) \\]\n",
            "\n",
            "### Step 3: Solve for \\( t \\)\n",
            "Expand and rearrange the equation:\n",
            "\\[ 60t = 90t - 90 \\]\n",
            "\\[ 90 - 60t = 90t - 60t \\]\n",
            "\\[ 30t = 90 \\]\n",
            "\\[ t = \\frac{90}{30} = 3 \\text{ hours} \\]\n",
            "\n",
            "### Step 4: Calculate the Time of Day\n",
            "Since \\( t \\) is the time in hours after 2 PM, the time at which the second train catches up to the first is:\n",
            "\\[ 2 \\text{ PM} + 3 \\text{ hours} = 5 \\text{ PM} \\]\n",
            "\n",
            "### Conclusion\n",
            "The second train catches up to the first train at 5 PM.\n",
            "Appeared 1 times.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background: linear-gradient(135deg, #001a70 0%, #0055d4 100%); color: white; padding: 25px; border-radius: 12px; text-align: center;\">\n",
        "    <h1 style=\"margin-bottom: 10px;\">üìö Exploring More Advanced Prompting Strategies</h1>\n",
        "</div>\n",
        "\n",
        "<div style=\"background: #ffffff; padding: 20px; border-radius: 10px; border-left: 6px solid #0055d4; margin-top: 20px;\">\n",
        "    <ul style=\"font-size: 16px; line-height: 1.8;\">\n",
        "        <li><strong>üß© Tree-of-Thought (ToT) Prompting:</strong> Explores multiple reasoning paths like a decision tree, helping the model evaluate and compare various solutions before choosing the best one.</li>\n",
        "        <li><strong>ü§ñ ReAct (Reasoning and Acting) Prompting:</strong> Combines reasoning steps with actions, including API calls or external tool usage. Ideal for interactive agents and dynamic decision-making tasks.</li>\n",
        "        <li><strong>üîÑ Reflexion Prompting:</strong> Encourages the model to critique its own responses and iteratively improve them, simulating self-correction and learning.</li>\n",
        "    </ul>\n",
        "</div>\n",
        "\n",
        "<div style=\"margin-top: 40px; text-align: center;\">\n",
        "    <h2 style=\"color: #001a70;\">‚úã Hands-On Task: Compare Prompting Strategies</h2>\n",
        "</div>\n",
        "\n",
        "<div style=\"background: #f5faff; padding: 20px; border-radius: 8px; border-left: 5px solid #0055d4;\">\n",
        "    <p style=\"font-size: 16px;\">\n",
        "        üìå <strong>Task Instructions:</strong><br>\n",
        "        - Experiment with <strong>Self-Consistency</strong>, <strong>Tree-of-Thought</strong>, and <strong>ReAct</strong> prompting methods.<br>\n",
        "        - Try to solve the following problem using each method and compare the results.\n",
        "    </p>\n",
        "</div>\n",
        "\n",
        "<div style=\"background: #ffffff; padding: 20px; border-radius: 10px; border-left: 6px solid #0055d4; margin-top: 20px;\">\n",
        "    <h3>üß† <strong>Challenge Problem:</strong></h3>\n",
        "    <p style=\"font-size: 16px;\">A farmer has chickens and rabbits in a cage. There are 35 heads and 94 legs. How many chickens and rabbits are there?</p>\n",
        "</div>\n",
        "\n",
        "<div style=\"margin-top: 40px;\">\n",
        "    <ul style=\"font-size: 16px; line-height: 1.8;\">\n",
        "        <li>Try different models (e.g., <code>gpt-3.5-turbo</code>, <code>gpt-4-turbo</code>, <code>gpt-o3</code>).</li>\n",
        "        <li>Experiment with different temperatures (e.g., <code>0.0</code>, <code>0.5</code>, <code>0.7</code>).</li>\n",
        "        <li>Use both direct prompts and advanced strategies like CoT, Self-Consistency, or ReAct.</li>\n",
        "    </ul>\n",
        "</div>\n",
        "\n",
        "<div style=\"margin-top: 40px; text-align: center;\">\n",
        "    <h2 style=\"color: #001a70;\">üìñ Observations</h2>\n",
        "</div>\n",
        "\n",
        "<div style=\"background: #ffffff; padding: 20px; border-radius: 10px; border-left: 6px solid #0055d4;\">\n",
        "    <ul style=\"font-size: 16px; line-height: 1.8;\">\n",
        "        <li><strong>Model and Strategy Used:</strong><br>_[Enter the model and prompting strategy you tried]_</li>\n",
        "        <li><strong>Was the Correct Answer Found?</strong><br>_[Yes/No. Explain briefly or attach a screenshot]_</li>\n",
        "        <li><strong>Key Takeaways (Max Half Page or Screenshot):</strong><br>_[Summarize how different strategies performed. What worked best? Why?]_</li>\n",
        "    </ul>\n",
        "</div>\n",
        "\n",
        "<div style=\"margin-top: 20px; text-align: center;\">\n",
        "    ‚úçÔ∏è <em>Hint: Try breaking down the problem into equations or ask the model to explain its steps before giving the final answer. Notice which strategies lead to faster and more accurate results!</em>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "Hfw5kDf5l_o_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# ‚úã Hands-On Code: Try Different Prompting Strategies and Models\n",
        "# ==========================\n",
        "\n",
        "# üìù Instructions:\n",
        "# - Change 'model_name' to try different models (e.g., \"gpt-3.5-turbo\", \"gpt-4-turbo\", \"gpt-o3\").\n",
        "# - Adjust 'temperature' to test how creativity affects reasoning.\n",
        "# - Try Self-Consistency by sampling multiple outputs and comparing answers.\n",
        "# - Optionally, explore Tree-of-Thought and ReAct patterns by modifying prompts.\n",
        "# ‚úÖ Your Experiment Starts Here üëá\n"
      ],
      "metadata": {
        "id": "5kYqO4FgkJd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "PROBLEM = \"A farmer has chickens and rabbits in a cage. There are 35 heads and 94 legs. How many chickens and rabbits are there?\""
      ],
      "metadata": {
        "id": "jic7qyL0v9gw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) Direct Prompting"
      ],
      "metadata": {
        "id": "duNjImdgwIPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Direct Prompting\n",
        "model_name = \"gpt-3.5-turbo\"\n",
        "temperature = 0.0\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Solve the problem and give ONLY the final answer in this format:\n",
        "Final: chickens=<number>, rabbits=<number>\n",
        "\n",
        "Problem: {PROBLEM}\n",
        "\"\"\"\n",
        "\n",
        "resp = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    temperature=temperature,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        ")\n",
        "\n",
        "print(resp.choices[0].message.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gx8soV3Tv1DX",
        "outputId": "6a0b704b-c98f-4f89-dffd-33dfb4d20189"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final: chickens=23, rabbits=12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Model and Strategy Used: gpt-3.5-turbo + Direct (temp=0.0)\n",
        "- Was the Correct Answer Found? Yes, returned chickens=23 and rabbits=12.\n",
        "- Key Takeaways: Direct prompting at low temperature produced a stable answer, but it didn‚Äôt show reasoning so it‚Äôs harder to verify correctness from the output alone."
      ],
      "metadata": {
        "id": "bLfLNruhx2ft"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) Advanced Prompting"
      ],
      "metadata": {
        "id": "krZ59lwVwMga"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## i) Chain-of-Thought (CoT)"
      ],
      "metadata": {
        "id": "PtYP3iL4wU2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Chain of Thought (CoT)\n",
        "\n",
        "model_name = \"gpt-3.5-turbo\"\n",
        "temperature = 0.0\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Solve the problem step by step using equations, then give the final answer.\n",
        "\n",
        "Problem: {PROBLEM}\n",
        "\n",
        "End with:\n",
        "Final: chickens=<number>, rabbits=<number>\n",
        "\"\"\"\n",
        "\n",
        "resp = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    temperature=temperature,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        ")\n",
        "\n",
        "print(resp.choices[0].message.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F27LQskiwMsY",
        "outputId": "75501790-b2e3-4e51-b9aa-bfa66a69eb19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let's denote the number of chickens as C and the number of rabbits as R.\n",
            "\n",
            "From the problem, we have two equations:\n",
            "1. C + R = 35 (total number of heads)\n",
            "2. 2C + 4R = 94 (total number of legs)\n",
            "\n",
            "Now, we can solve these two equations simultaneously.\n",
            "\n",
            "From equation 1:\n",
            "C = 35 - R\n",
            "\n",
            "Substitute this into equation 2:\n",
            "2(35 - R) + 4R = 94\n",
            "70 - 2R + 4R = 94\n",
            "2R = 24\n",
            "R = 12\n",
            "\n",
            "Now, substitute R back into C = 35 - R:\n",
            "C = 35 - 12\n",
            "C = 23\n",
            "\n",
            "Therefore, there are 23 chickens and 12 rabbits.\n",
            "\n",
            "Final: chickens=23, rabbits=12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Model and Strategy Used: gpt-3.5-turbo + CoT (temp=0.0)\n",
        "- Was the Correct Answer Found? Yes.\n",
        "- Key Takeaways: CoT made the logic easy to follow (equations for heads and legs). It increased transparency compared to direct prompting, with similar accuracy at low temperature."
      ],
      "metadata": {
        "id": "LQFeKblzyCId"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ii) Self-Consistency"
      ],
      "metadata": {
        "id": "OGUuEs8AwtkT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Self-Consistency\n",
        "\n",
        "model_name = \"gpt-3.5-turbo\"\n",
        "temperature = 0.7\n",
        "n_samples = 7\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Solve the problem and output ONLY:\n",
        "Final: chickens=<number>, rabbits=<number>\n",
        "\n",
        "Problem: {PROBLEM}\n",
        "\"\"\"\n",
        "\n",
        "def extract_pair(text: str):\n",
        "    m = re.search(r\"chickens\\s*=\\s*(\\d+)\\s*,\\s*rabbits\\s*=\\s*(\\d+)\", text, re.I)\n",
        "    return (int(m.group(1)), int(m.group(2))) if m else None\n",
        "\n",
        "answers = []\n",
        "raw = []\n",
        "\n",
        "for _ in range(n_samples):\n",
        "    resp = client.chat.completions.create(\n",
        "        model=model_name,\n",
        "        temperature=temperature,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    out = resp.choices[0].message.content.strip()\n",
        "    raw.append(out)\n",
        "    pair = extract_pair(out)\n",
        "    if pair:\n",
        "        answers.append(pair)\n",
        "\n",
        "print(\"Outputs:\")\n",
        "for i, out in enumerate(raw, 1):\n",
        "    print(f\"{i}. {out}\")\n",
        "\n",
        "if answers:\n",
        "    vote = Counter(answers).most_common(1)[0]\n",
        "    print(\"\\nMajority vote:\", vote[0], \"count:\", vote[1])\n",
        "else:\n",
        "    print(\"\\nCould not parse answers.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnSxA6brw1dw",
        "outputId": "230521a8-44c2-4a28-a8cf-e596a87336f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outputs:\n",
            "1. Final: chickens=23, rabbits=12\n",
            "2. Final: chickens=23, rabbits=12\n",
            "3. Final: chickens=23, rabbits=12\n",
            "4. Final: chickens=23, rabbits=12\n",
            "5. Final: chickens=23, rabbits=12\n",
            "6. Final: chickens=23, rabbits=12\n",
            "7. Final: chickens=23, rabbits=12\n",
            "\n",
            "Majority vote: (23, 12) count: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Model and Strategy Used: gpt-3.5-turbo + Self-Consistency (temp=0.7, n=7)\n",
        "- Was the Correct Answer Found? Yes (majority vote gave 23 chickens, 12 rabbits).\n",
        "- Key Takeaways: Higher temperature caused more variation across runs, but self-consistency improved reliability by voting across multiple samples."
      ],
      "metadata": {
        "id": "2hoJjR65yGkE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## iii) Tree-of-Thought"
      ],
      "metadata": {
        "id": "xNF1Q_eSxC9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tree-of-Thought\n",
        "\n",
        "model_name = \"gpt-4-turbo\"\n",
        "temperature = 0.5\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Use a Tree-of-Thought approach:\n",
        "1) Propose 3 different solution paths.\n",
        "2) Briefly evaluate which is most reliable.\n",
        "3) Solve using the best path.\n",
        "\n",
        "Problem: {PROBLEM}\n",
        "\n",
        "End with:\n",
        "Final: chickens=<number>, rabbits=<number>\n",
        "\"\"\"\n",
        "\n",
        "resp = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    temperature=temperature,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        ")\n",
        "\n",
        "print(resp.choices[0].message.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrjb6DQcxFGf",
        "outputId": "fb9da6a5-5ce8-48e9-90bd-97f2760534de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Step 1: Propose 3 Different Solution Paths\n",
            "\n",
            "**Solution Path 1: Algebraic Equations**\n",
            "- Use algebra to set up equations based on the number of heads and legs.\n",
            "- Equation 1 (heads): \\( C + R = 35 \\) (where C is the number of chickens and R is the number of rabbits)\n",
            "- Equation 2 (legs): \\( 2C + 4R = 94 \\)\n",
            "- Solve the system of equations to find values for C and R.\n",
            "\n",
            "**Solution Path 2: Elimination Method**\n",
            "- From the algebraic approach, manipulate the equations to eliminate one variable and solve for the other.\n",
            "- Multiply the heads equation by 2 and subtract it from the legs equation to eliminate chickens and solve directly for rabbits.\n",
            "- Substitute back to find the number of chickens.\n",
            "\n",
            "**Solution Path 3: Iterative Testing**\n",
            "- Start with 0 rabbits and calculate if the remaining animals (all chickens) can satisfy the total leg count.\n",
            "- Incrementally increase the number of rabbits and decrease chickens correspondingly, checking each time if the leg count matches.\n",
            "- Continue until a valid solution is found.\n",
            "\n",
            "### Step 2: Briefly Evaluate Which is Most Reliable\n",
            "\n",
            "- **Algebraic Equations** and **Elimination Method** are both direct and use systematic mathematical approaches, ensuring accuracy and efficiency. These methods provide exact answers and are less prone to error compared to iterative testing, which can be more time-consuming and error-prone.\n",
            "- **Iterative Testing** is intuitive and doesn't require algebraic manipulation, but it's less efficient and more suitable for problems with smaller numbers or when quick approximations are needed.\n",
            "\n",
            "Given the context and the need for precision, **Solution Path 1 (Algebraic Equations)** is the most reliable as it provides a straightforward, systematic approach to finding the exact numbers of chickens and rabbits.\n",
            "\n",
            "### Step 3: Solve Using the Best Path\n",
            "\n",
            "**Using Algebraic Equations:**\n",
            "\n",
            "1. Set up the equations based on the given information:\n",
            "   - \\( C + R = 35 \\)  (Total heads)\n",
            "   - \\( 2C + 4R = 94 \\)  (Total legs)\n",
            "\n",
            "2. Solve for one of the variables:\n",
            "   - Multiply the first equation by 2:\n",
            "     \\[ 2C + 2R = 70 \\]\n",
            "   - Subtract this from the second equation:\n",
            "     \\[ (2C + 4R) - (2C + 2R) = 94 - 70 \\]\n",
            "     \\[ 2R = 24 \\]\n",
            "   - Divide by 2:\n",
            "     \\[ R = 12 \\]\n",
            "\n",
            "3. Substitute \\( R = 12 \\) back into the first equation to find \\( C \\):\n",
            "   - \\( C + 12 = 35 \\)\n",
            "   - \\( C = 35 - 12 = 23 \\)\n",
            "\n",
            "**Final: chickens=23, rabbits=12**\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Model and Strategy Used: gpt-4-turbo + Tree-of-Thought (temp=0.5)\n",
        "- Was the Correct Answer Found? Yes.\n",
        "- Key Takeaways: ToT encouraged exploring multiple approaches (equations, elimination, sanity check). This improved confidence and reduced the chance of a single-path mistake."
      ],
      "metadata": {
        "id": "Xti5YDs1yOWP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## iv) ReAct"
      ],
      "metadata": {
        "id": "kznBxdnqxXvw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ReAct\n",
        "\n",
        "model_name = \"gpt-4-turbo\"\n",
        "temperature = 0.0\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Use ReAct format. Alternate:\n",
        "Reason: what you will do next\n",
        "Act: the equation/calculation\n",
        "\n",
        "Keep it short.\n",
        "\n",
        "Problem: {PROBLEM}\n",
        "\n",
        "End with:\n",
        "Final: chickens=<number>, rabbits=<number>\n",
        "\"\"\"\n",
        "\n",
        "resp = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    temperature=temperature,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        ")\n",
        "\n",
        "print(resp.choices[0].message.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzxQcK86xZmO",
        "outputId": "9b60c81c-5104-4da5-f7c8-5fce6be8b745"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reason: Define variables for chickens and rabbits.\n",
            "Act: Let \\( c \\) be the number of chickens and \\( r \\) be the number of rabbits.\n",
            "\n",
            "Reason: Set up an equation based on the number of heads.\n",
            "Act: \\( c + r = 35 \\)\n",
            "\n",
            "Reason: Set up an equation based on the number of legs.\n",
            "Act: \\( 2c + 4r = 94 \\)\n",
            "\n",
            "Reason: Solve the system of equations by substitution or elimination.\n",
            "Act: Multiply the first equation by 2: \\( 2c + 2r = 70 \\)\n",
            "\n",
            "Reason: Subtract the modified first equation from the second equation to eliminate \\( c \\).\n",
            "Act: \\( (2c + 4r) - (2c + 2r) = 94 - 70 \\)  \n",
            "    \\( 2r = 24 \\)\n",
            "\n",
            "Reason: Solve for \\( r \\).\n",
            "Act: \\( r = 24 / 2 = 12 \\)\n",
            "\n",
            "Reason: Substitute \\( r = 12 \\) back into the first equation to find \\( c \\).\n",
            "Act: \\( c + 12 = 35 \\)  \n",
            "    \\( c = 35 - 12 = 23 \\)\n",
            "\n",
            "Final: chickens=23, rabbits=12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Model and Strategy Used: gpt-4-turbo + ReAct (temp=0.0)\n",
        "- Was the Correct Answer Found? Yes.\n",
        "- Key Takeaways: ReAct produced the most structured reasoning by separating planning from calculation. At low temperature it stayed consistent and avoided arithmetic slips."
      ],
      "metadata": {
        "id": "Dn31i8kGyUNx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background: linear-gradient(135deg, #001a70 0%, #0055d4 100%); color: white; padding: 25px; border-radius: 12px; text-align: center;\">\n",
        "    <h1 style=\"margin-bottom: 10px;\">üìå Conclusion</h1>\n",
        "</div>\n",
        "\n",
        "<div style=\"background: #ffffff; padding: 20px; border-radius: 10px; border-left: 6px solid #0055d4; margin-top: 20px;\">\n",
        "    <p style=\"font-size: 16px; line-height: 1.8;\">\n",
        "        In this hands-on exploration, different advanced prompting strategies were tested to solve reasoning-based challenges.\n",
        "        Through experimenting with <strong>Chain-of-Thought (CoT)</strong>, <strong>Self-Consistency</strong>, and other methods,\n",
        "        the following key insights were observed:\n",
        "    </p>\n",
        "    <ul style=\"font-size: 16px; line-height: 1.8;\">\n",
        "        <li>Advanced prompting techniques significantly improve model performance, especially on complex, multi-step problems.</li>\n",
        "        <li>Changing the <strong>model type</strong> and <strong>temperature</strong> can drastically affect reasoning quality and creativity.</li>\n",
        "        <li>Some strategies, like <strong>Self-Consistency</strong>, help reduce random errors by exploring multiple reasoning paths.</li>\n",
        "        <li>For ambiguous or challenging problems, combining strategies (e.g., CoT + Self-Consistency) often leads to the most reliable results.</li>\n",
        "    </ul>\n",
        "</div>\n",
        "\n",
        "<div style=\"background: #f5faff; padding: 20px; border-radius: 8px; border-left: 5px solid #0055d4; margin-top: 20px;\">\n",
        "    <p style=\"font-size: 16px; font-style: italic;\">\n",
        "        üìñ <em>Remember: Prompt engineering is both an art and a science. The more you experiment, the better you understand how to guide LLMs effectively!</em>\n",
        "    </p>\n",
        "</div>\n",
        "\n",
        "<div style=\"margin-top: 40px; text-align: center;\">\n",
        "    <h3 style=\"color: #001a70;\">‚úçÔ∏è Final Reflection</h3>\n",
        "</div>\n",
        "\n",
        "<div style=\"background: #ffffff; padding: 20px; border-radius: 10px; border-left: 6px solid #0055d4;\">\n",
        "    <p style=\"font-size: 16px;\">\n",
        "        _[Write 2-3 sentences summarizing what you personally learned about prompting strategies and how model selection or temperature influenced the results.]_\n",
        "    </p>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "sivjpWXsmlUJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Reflection\n",
        "\n",
        "Direct Prompting provided the correct answer in a quick manner but lacked any level of visibility. Chain of Thought improved the level of clarity and made it easier to verify the solution without compromising accuracy significantly. Self-Consistency was helpful when the temperature level was higher, as individual responses varied. Using a majority vote improved accuracy. Tree of Thought prompted thinking of multiple solution paths before arriving at a final answer, which improved the level of correctness. ReAct provided the best level of clarity and structure in the solution by dividing the planning and calculation processes, which eliminated any errors in the final answer."
      ],
      "metadata": {
        "id": "COdLLrk9y77H"
      }
    }
  ]
}